
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
#
#                             Meta Information
#                            __________________
# 
#
# Header:
#
#    Program:  “DjiSeasonMonthPeg”
#    Purpose:  Pegging the seasonal waves of the DJI index by month.
#
#    Copyright © 2020  Kenwave.com and MintKit.com 
#
#
# MIT Mode of License:
#
# Permission is hereby granted, free of charge, to any person obtaining a 
# copy of this software and associated documentation files (the “Software”),
# to deal in the Software without restriction, including without limitation 
# the rights to use, copy, modify, merge, publish, distribute, sublicense, 
# and/or sell copies of the Software, and to permit persons to whom the 
# Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, 
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHOR(S) OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER 
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING 
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER 
# DEALINGS IN THE SOFTWARE.
#
#
#=== Prime Reference for the Program:
#
#    Basic Models of Complex Systems: 
#    Crux of the Duplex Method plus 
#    Case Study of the Dow Stock Index
#    (Kim, 2020)
#
# The program here serves as the groundwork for the report named above. 
#
#
#=== Keywords:
#
#    Duplex, Complex Systems, Binomial Test, Markets, Models, Stocks, 
#    Waves, Cycles, Efficiency, EMH, Random Walk, R, Program, Code, 
#    Dow, Index, Finance, Economics, Nonparametric, Statistics
#    
#
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



############################################################################
#
#
#               Modeling Seasonal Patterns in the Stock Market
#              ________________________________________________
#  
#
#=== Objective
#
# To present a duplex framework for modeling complex systems with the  
# utmost of simplicity, clarity and efficacy. The merits of the binary 
# schema arise, for instance, in dispelling the welter of myths and 
# misconceptions in finance and economics. For this purpose, a springboard 
# par excellence lies in the seasonal patterns of the stock market 
# throughout the year. 
#
# The descriptive model spotlighted here refutes the ruling credo of 
# efficient markets that lies at the heart of financial economics. To this 
# end, the battery of disproofs centers on the subtle but recurrent 
# waves in the stock market as showcased by the monthly returns of the Dow
# Jones Industrial Average (DJI). 
# 
# A related task is to demonstrate the mettle of the R language along with
# the software platform. The minimalist program shuns the use of advanced 
# functions in R such as specialized commands meant to streamline the 
# analysis of time-series data. Instead, the code employs only a tiny subset
# of the inbuilt features within the kernel module – also known as “Base R” 
# – of the software platform. 
#
# In short, this program encodes a trenchant model of the bourse through a 
# lean set of functions in the R language coupled with the core module of 
# the software engine. Despite its simplicity, the script conveys an 
# intuitive and practical model of a complex system – namely, the stock
# market – that has long confounded the mass of practitioners as well as 
# researchers. A direct consequence is to uproot the hoary dogma of efficient
# markets that undergirds the entire edifice of financial economics.
# 
#
#=== Prime Reference for the Code
# 
# This document comprises the program behind the report named in the Meta 
# section above. The latter pamphlet discusses the substantive issues 
# behind the code, ranging from the choice of the dataset to the design of 
# the assays. An example involves the logical flaws behind the Efficient 
# Market Hypothesis or the key assumptions behind a statistical test.
#
# On the other hand, the report pays scant attention to logistic issues 
# aside from some passing remarks such as the source of the dataset in 
# cyberspace. A notable instance of the exclusion concerns the nitty-gritty 
# of obtaining the raw data, or the assignment of the working directory for 
# the R system. Instead, the administrative tasks are explained in detail in
# the next section of the document in hand.
# 
# To sum up, the weighty aspects of the program are discussed in the report
# for which the listing here serves as a capsule and a supplement. To curtail
# redundancy, the statements in the following collation come with only a 
# modicum of explanation. 
# 
# To complement the spartan narrative, however, the script below contains 
# pointers in the form of headings that correspond to sundry sections within 
# the report itself. In this way, the interested reader may refer to the 
# pamphlet for a full account of the primal issues ranging from the logic 
# behind the overall layout of the program to the motive for specific assays. 
#
#
#=== Quirks of the Stock Market and Dataset
# 
# The case study centers on the Dow Jones Industrial Average, also known by 
# the shorthand of DJI. The data series is available at Yahoo Finance, the 
# favorite portal of the investing public. From a larger stance, a big
# stockpile of data in any domain is apt to contain entries that are 
# incorrect, incomplete, misleading and/or inconsistent. The repository at 
# Yahoo is no exception to the rule.
#
# On one hand, at least one form of idiosyncrasy at the Web site is doubtless
# deliberate and intended as a convenience for the user. In particular, a 
# dynamic display of the historical record for the DJI on a browser presents 
# all the values to the accuracy of two decimal places. 
#
# On the other hand, a static file which is downloaded from the same portal 
# lists the corresponding factoids up to the exactness of six decimal places.
# (In some cases, five or fewer decimals may be shown on a spreadsheet if the 
# cells are too narrow.)
#  
# To bring up another quirk, a download of the weekly data marks the starting 
# date as Monday, 28 January 1985. Meanwhile, the corresponding set of daily 
# records begins on Tuesday, 29 January 1985.
# 
# If we were interested in all the extreme values over the course of each 
# month, we ought to begin with February that year. In actuality, though, we 
# focus only on the closing values at the end of each month. For this reason, 
# we could start with the final price at the close of either month. 
#
# For the sake of conceptual simplicity, however, we will begin with the 
# first month of 1985. In that case, we need the records until January 2020 
# in order to calculate a series of monthly returns for a whole number of 
# years.
#
# In these and other ways, we ought to keep in mind the quirky aspects of
# any dataset in hand. Although the issues aired in this section are generic 
# matters, they do have some bearing on the current study in particular. 
#
# Regardless of such niceties, however, the main requirement for a worthwhile 
# assay is the reasonable premise that the closing values of the monthly 
# readings display a modicum of accuracy. From a different angle, even a 
# fixed and systematic bias to the upside or downside on a percentage basis 
# would result in conclusions that prove to be just as valid. 
#
#
#===========================================================================
#
#
#                            Prep for Startup 
#                           __________________
#
#
#
#=== Set the Working Directory
#
# The first step is to specify the working directory for the input and output 
# of data. When the R system starts up, it will select a directory for the 
# files to be read and/or written. You may check the current location of the 
# working directory by issuing the following command:

getwd()

# The system will respond with a printout such as the following:
#
#    [1] "C:/Users/Myname/Documents"
#
# In the foregoing output, the tag of “[1]” denotes the first (and in this 
# case, the only) item in the response provided by the system. The rest of 
# the printout conveys the following information: the current directory is 
# the Documents folder on the C drive for the user called Myname. 
# 
# If the folder chosen by the system is a suitable location for your files, 
# then you may leave the setting alone and move on to the next step. 
#    
# On the other hand, suppose that you would like to use a different folder.
# To illustrate, we will assume that you prefer a directory named Testbed 
# which you created in advance and placed on the Desktop. In that case, you
# could issue a suitable instruction such as either of the following 
# commands:
#
     setwd("../Desktop/Testbed")
#    setwd("C:/Users/Myname/Desktop/Testbed")
#
# At most, only one of the foregoing commands should be used. In that case, 
# any unused statement should be preceded by a hash mark (#) in order to 
# denote it as a comment rather than an instruction to the R system. 
#
# After this step, you should confirm any change of location by running the 
# “getwd()” command once more. From this point onward, we will assume that 
# the current working directory has been set as you wish.
#
#
#=== Fetch the Data
# 
# You may use a Web browser to obtain the historical data for the Dow Jones 
# index from Yahoo Finance (finance.yahoo.com). The dataset desired is 
# the record of monthly prices from January 1985 to January 2020. 
#
# In fetching the data, your computer will create a new file and place it 
# in a directory called Downloads as the default choice of location. The new 
# document is automatically given the name of “^DJI.csv”. In displaying the 
# file, however, your computer is likely to hide the extension that denotes 
# the document type (“.csv”) and instead list the item more tersely as 
# “^DJI”. 
#    
# For the sake of convenience and decorum, we will make a couple of logistic 
# tweaks. The first step is to modify the name of the file from “^DJI” to a 
# more descriptive label in the form of “DjiMonth1985-2020”.
#    
# If the current directory differs from the Downloads folder, then your next
# task is to move the renamed file into the location specified earlier. The
# switchover will simplify the task of fetching the contents from the R 
# platform later on. 
#    
# By this juncture, the data file has been renamed and emplaced in the 
# current working directory. The next step is to load the dataset into the 
# R system.
#
#
#=== Read in the Data
#
# After returning to the R platform, you may access the newborn file located 
# in the working directory. The contents of this file should be read into a 
# data frame called Raw. The latter name features an initial capital letter 
# to serve as a mnemonic that the given object is a full-fledged table rather
# than a simpler construct such as a character string or a numeric vector. 
#
# On the other hand, exceptions to the naming convention may arise in the 
# case of labels assigned by external parties. An example involves the
# Boolean values of TRUE and FALSE which are built-in primitives of the R
# system. Another instance concerns the column of closing values of the DJI 
# which has been dubbed as Close by the compiler of the data.
#
# A simple way to copy the dataset into the current workspace is to issue the 
# following command. 

Raw = read.csv("DjiMonth1985-2020.csv")

# If the system responds with an error message, the most likely cause is a
# mismatch between the working directory and the location of the data file.
# In that case, you should rectify the discrepancy. Depending on 
# circumstances, the R engine may continue to issue rude messages. If so, 
# your best bet is to quit the program and shut it down entirely. Next, 
# confirm that the steps described in the previous subsections have been 
# taken properly, including the use of the “setwd()” command at most once. 
# Then restart the system.
#
# At this stage, you should verify that the dataset has been cloned 
# correctly. You may use the following command to print out the first 
# handful of rows:

head(Raw)

# You should do likewise for the last portion comprising half a dozen 
# records:

tail(Raw)

# By this point, you have copied the contents of the external file into a
# data frame called Raw then confirmed the result. You may now move on to 
# the main task of analyzing the input.
#
#
#___________________________________________________________________________
#
#
#                               Body of Code
#                              ______________
#
#
# This section conveys the body of the script behind the report named in the 
# Meta section at the beginning of this document. The lines of code shown 
# below, including the output of figures, appear in the same order as the 
# results presented in the pamphlet.
#
# By this juncture, you should have taken the leadoff steps described in the 
# previous section. In that case, the script as a whole represents a coherent 
# program rather than a haphazard collection of snippets of code. For this 
# reason, the entire program – including the statements discussed in the Prep
# section above – may be executed in a single pass from the Editor pane of 
# the R platform.
# 
# After such a run, an ancillary issue concerns the charts created by the 
# system along the way. Suppose that you deployed the program while using a 
# friendly interface such as the RStudio package; in that case, you may 
# easily access the graphics by clicking on the arrows under the Plots tab of
# the output pane. However, if you used only the kernel module (namely, Base
# R) of the software platform to execute the script, then you should return 
# to the Editor pane and rerun any of the plotting commands in order to view 
# the attendant output.
#
# To round up, the script below underpins the research report. For each 
# segment, you should refer to the corresponding section of the guide for 
# a detailed explanation of the motive for the code as well as other vital 
# matters such as the interpretation of the results.
#
#
#---------------------------------------------------------------------------



####  Code for Statistical Assays  #### 



#=== Survey of the Data


## Create Fig. 1: Monthly level of DJI from January 1985 to January 2020.

plot(Raw$Close, type='l', col='magenta', xlab='Month', ylab='DJI')


# To simplify access later on to the columns of the Raw table.

attach(Raw)

# Henceforth we may – for instance – refer to the vector of closing values 
# in the Raw array as “Close” rather than “Raw$Close”.


## Fig. 2: Log to base 10 of DJI by month over the entire timespan.

plot(log10(Close),type='l',col='magenta',xlab='Month',ylab='Log of DJI')



#=== Gauging the Monthly Returns


# The length (len) of the Raw table is the same as that of the Close column. 
# The number of monthly returns (n) equals 1 less than the number of records 
# in Raw. 

len = length(Close)
n = len - 1


# Create the adjunct table wherein each record contains the date plus the 
# closing values for the current month and the next.

A = cbind(Date[1:n], Close[1:n], Close[2:len])


# Check that the table has been formed properly by printing the first three
# records; and likewise for the last triad.

head(A,3)
tail(A,3)


# Form the vector of monthly returns, in percent, for each record in table A. 

ret = 100 * ( A[ , 3] - A[ , 2] ) / A[ , 2]


## Fig. 3: Forward monthly return for DJI from 1985 to 2019.
## The closing price in January 2020 is used for pegging the forward return 
## from the standpoint of December 2019.

plot(ret, type='l', col='magenta', xlab='Month', ylab='Return (%)')


# The B board will serve as a baseline or backbone for further analysis.

B = data.frame(Date[1:n], Close[1:n], ret)


# Verify the B board.

head(B,3)
tail(B, 3)



#=== Crafting the Descriptive Models


# Calculate the magnification factor (wax) for the price level over the 
# entire timeline. Then find the geometric mean of the rate of ascent, in 
# percent per month, and print it out.

wax = A[n,3] / A[1,2]
gm.wax = wax^(1/n)
gm.r = 100 * (gm.wax - 1)
gm.r


# Form the C cache to serve as the substrate for gleaning the monthly gains 
# on average. Each row of the matrix represents a given year, while each
# column reflects the pertinent month of the year.
 
C = matrix(ret, ncol=12, byrow=TRUE)


# Confirm the C cache by printing the first three records; and likewise for 
# the last triplex.

head(C, 3)
tail(C, 3)


# Find the MEAN value of each column to get the vector of monthly gains.

zig = colMeans(C)


## Fig. 4: Mean return for each month of the year.

plot(1:12,zig,type='b',col='blue',xlab='Month',ylab='Return (%)')
abline(h = 0, col='red')  # Draw a red, horizontal line through the origin.


## Fig. 5: Boxplot of forward monthly returns.

bp = boxplot(C, col='yellow', xlab='Month', ylab='Return (%)')
bp           # Print out the contents of bp.


# Extract the row of MEDIAN values from the “stats” module in bp.

zag = bp$stats[3, ]


# Find the absolute values of the errors due to the zig and zag vectors.

aeZig = abs(ret - zig)
aeZag = abs(ret - zag)


# Get the MEAN of the absolute values of the errors due to the zig as well 
# as zag vectors.

mean(aeZig); mean(aeZag) 


# Do likewise for the MEDIAN of the absolute values of the errors due to the 
# zig as well as zag arrays.

median(aeZig); median(aeZag)


# Form the vector of errors for each of the Idle, Drift, and Sway Models 
# respectively.

eI = ret
eD = ret - gm.r
eS = ret - zag


## Fig. 6: Boxplots of errors by model.

boxplot(eI, eD, eS, names=c('Idle','Drift','Sway'),
        ylab= 'Return (%)', col=c('orange','yellow','green'))


# Find the variance of the errors for each of the Idle, Drift, and Sway 
# Models.

var(eI) ; var(eD) ; var(eS)


# Get the absolute values of the errors for each Model.

aeI = abs(eI) 
aeD = abs(eD) 
aeS = abs(eS)


# Find the MEAN of the absolute values of the errors for each Model.

mean(aeI) ; mean(aeD) ; mean(aeS)


# Get the MEDIAN of the absolute values of the errors for each template.

mad(eI, constant=1) ; mad(eD, constant=1) ; mad(eS, constant=1)

# In each command above, an argument called “constant” has been set to 1. 
# This clause ensures that the results of the computation are better suited
# to our current assay. As a counterpoint, suppose that the “constant” 
# modifier had been omitted from the foregoing decrees. In that case, the 
# “mad” routine would have applied a scaling factor of 1.4826. More 
# precisely, a plain command of the form “mad(eI)” would be equivalent to 
# the following diktat: “1.4826 * mad(eI, constant=1)”.
#
# The multiplier of 1.4826 serves to calibrate the MAD value against the 
# standard deviation (SD) of the sample. The rationale is as follows. The 
# expected value of the boosted version of the MAD statistic — that is, 
# after multiplication by 1.4826 — equals the standard deviation if the 
# sample were to come from a normal distribution (Leys, 2013; Ruppert, 2010).
#
# From a pragmatic stance, then, the bulked-up result would be apropos if we
# wanted to compare the output of the “mad” command directly to the standard 
# deviation of the sample. (From a larger stance, the SD may serve as a 
# proxy for the root mean square of the errors whether or not the data 
# happen to spring from a Gaussian ogive.) At this stage, we wish to assess 
# the mean level of the absolute error as well as the MAD value against the 
# standard deviation. For this reason, we use the plain value of MAD rather 
# than its boosted version.


# For each Model, find the ratio of the MEAN of the absolute errors to the 
# SD of the errors; and likewise the quotient of the MAD to the SD. 

mean(aeI)/sd(eI); mad(eI, constant=1)/sd(eI)
mean(aeD)/sd(eD); mad(eD, constant=1)/sd(eD)
mean(aeS)/sd(eS); mad(eS, constant=1)/sd(eS)



#=== Overall Direction of Movement


# Check whether each element of ret is positive. Next, convert any value of 
# TRUE to 1; and FALSE to 0. Then compute nUp: the number of positive values 
# in the ret vector.

boolUp = ret > 0
iUp = as.integer(boolUp) 
nUp = sum(iUp)


# Assess the Idle Model for which the null hypothesis posits equal odds of 
# moving upward or not. The checkup entails a two-tailed binomial test.

binom.test(nUp, n, p = 0.5, alternative = "two.sided")


# Find nUpD, the number of positive entries in the error vector eD; we make 
# use of the fact that the “sum()” function adds up the number of TRUE 
# entries when its argument is a vector of Boolean values. Then we match the 
# result against n, the total number of cases, to conduct a binomial test
# of proportions for the Drift template. The alternative hypothesis entails 
# a two-sided probe.

nUpD = sum(eD > 0)
binom.test(nUpD, n, p = 0.5, alt = "two.sided")


# Do likewise for the error vector eS, and thereby vet the Sway Model.

nUpS = sum(eS > 0)
binom.test(nUpS, n, p = 0.5, alt = "two.sided")



#=== Global Score of Errors


# First, compare each error in the aeD vector against its counterpart in aeI. 
# Then use winDI, the number of wins (meaning smaller absolute errors) for 
# the Drift Model against the Idle version, along with the number of cases, 
# to conduct a one-sided test for superior performance. 

winDI = aeD < aeI
nwinDI = sum(winDI)
binom.test(nwinDI, n, p = 0.5, alt = "greater")


# Do likewise in testing the aeS vector against aeI. In this way, we check
# whether the Sway Model trumps the Idle icon.

nwinSI = sum(aeS < aeI)
binom.test(nwinSI, n, p = 0.5, alt = "greater")


# And once more for the aeS vector against the aeD.

nwinSD = sum(aeS < aeD)
binom.test(nwinSD, n, p = 0.5, alt = "greater")



#=== Intra-year Warp of Direction


# Count the number of upturns for October regardless of the moves by any 
# other month. Also do likewise for August. The second statement below uses 
# the fact that the “sum” command performs the “as.integer()” function 
# automatically when the argument represents a vector of Boolean values.

nOct = sum(as.integer(C[ ,10] > 0))
nAug = sum(C[ ,8] > 0)               


# Get the number of years as one-twelfth of the count of cases.
 
nYear = n/12


# Find the fraction of positive returns for October as well as August.
# Then print out the results.

fOct = nOct/nYear  
fAug = nAug/nYear  
fOct ; fAug


# Perform a binomial test for independent samples; that is, the observations 
# for August and October are not paired by the year of occurrence. The null 
# hypothesis presumes that the two months display equal prospects of moving 
# higher, while the alternative premise avers that any discrepancy in the 
# ratios is as likely to be positive as negative. The upshot is a two-tailed 
# test of the proportions.

binom.test(nOct, nYear, p = fAug, alt = "two.sided")



#=== Intra-year Clash of Returns


# Count the number of times that October trumps August in the same year. 
# That is, the two months are paired by the year of occurrence.

nOctWin = sum(C[ ,10] > C[ ,8])


# Conduct a binomial probe wherein the alternative hypothesis entails a 
# one-tailed test to the upside. In addition to the pairing of returns by
# year, this assay features another distinction compared to the previous
# checkup; namely, a one-tailed test rather than a two-tailed probe.

binom.test(nOctWin, nYear, p = 0.5, alt = "greater")



###############################  End of Code  ###############################
